/**
 * Vercel Serverless Function - Video Generation API
 * Generates videos using Google Veo API first, with FAL.ai as fallback
 */

import type { VercelRequest, VercelResponse } from "@vercel/node";
import { GoogleGenAI } from "@google/genai";
import { fal } from "@fal-ai/client";
import { put } from "@vercel/blob";
import {
  requireAuth,
  applyRateLimit,
  createRateLimitKey,
  setupCors,
} from "../db/_helpers";
import { trackAIOperation, createUsageContext } from "./_helpers/index";

// Configure fal client
const configureFal = () => {
  const apiKey = process.env.FAL_KEY;
  if (!apiKey) {
    throw new Error("FAL_KEY environment variable is not configured");
  }
  fal.config({ credentials: apiKey });
};

interface FalVideoResponse {
  data?: {
    video: { url: string };
    video_id?: string;
  };
  video?: { url: string };
}

// Generate video using Google Veo API directly
async function generateVideoWithGoogleVeo(
  prompt: string,
  aspectRatio: string,
  imageUrl: string | undefined,
  _sceneDuration: number | undefined,
  _generateAudio: boolean = true,
): Promise<string> {
  const apiKey = process.env.GEMINI_API_KEY;
  if (!apiKey) {
    throw new Error("GEMINI_API_KEY not configured");
  }

  const ai = new GoogleGenAI({ apiKey });
  const isHttpUrl = imageUrl && imageUrl.startsWith("http");
  const mode = isHttpUrl ? "image-to-video" : "text-to-video";

  console.log(`[Video API] Google Veo ${mode} (720p | ${aspectRatio})...`);

  // Build request parameters according to SDK specs
  const generateParams: any = {
    model: "veo-3.1-fast-generate-preview",
    prompt,
    config: {
      numberOfVideos: 1,
      resolution: "720p",
      aspectRatio,
    },
  };

  // Add image for image-to-video mode
  if (isHttpUrl) {
    const imageResponse = await fetch(imageUrl);
    const imageArrayBuffer = await imageResponse.arrayBuffer();
    const imageBase64 = Buffer.from(imageArrayBuffer).toString("base64");
    const contentType =
      imageResponse.headers.get("content-type") || "image/jpeg";

    generateParams.image = {
      imageBytes: imageBase64,
      mimeType: contentType,
    };
  }

  // Start video generation (async operation)
  let operation = await ai.models.generateVideos(generateParams);

  // Poll for completion (max 5 minutes)
  const maxWaitTime = 5 * 60 * 1000;
  const pollInterval = 10000;
  const startPoll = Date.now();

  while (!operation.done) {
    if (Date.now() - startPoll > maxWaitTime) {
      throw new Error("Video generation timed out after 5 minutes");
    }

    await new Promise((resolve) => setTimeout(resolve, pollInterval));
    operation = await ai.operations.getVideosOperation({ operation });
  }

  console.log(`[Video API] Google Veo completed`);

  // Get video URL from response
  const generatedVideos = (operation as any).response?.generatedVideos;
  if (!generatedVideos || generatedVideos.length === 0) {
    throw new Error("No videos generated by Google Veo");
  }

  const videoUri = generatedVideos[0].video?.uri;
  if (!videoUri) {
    throw new Error("Invalid video response from Google Veo");
  }

  // Append API key to download the video
  const videoUrl = `${videoUri}&key=${apiKey}`;
  return videoUrl;
}

// Generate video using FAL.ai (fallback)
async function generateVideoWithFal(
  prompt: string,
  aspectRatio: string,
  model: string,
  imageUrl: string | undefined,
  sceneDuration: number | undefined,
  generateAudio: boolean = true,
): Promise<string> {
  configureFal();

  const isHttpUrl = imageUrl && imageUrl.startsWith("http");
  const mode = isHttpUrl ? "image-to-video" : "text-to-video";

  if (model === "sora-2") {
    const duration = 12;
    let result: FalVideoResponse;

    if (isHttpUrl) {
      console.log(`[Video API] FAL.ai Sora 2 image-to-video (${duration}s)...`);
      result = (await fal.subscribe("fal-ai/sora-2/image-to-video", {
        input: {
          prompt,
          image_url: imageUrl,
          resolution: "720p",
          aspect_ratio: aspectRatio,
          duration: duration as any,
          delete_video: false,
        },
        logs: true,
      })) as FalVideoResponse;
    } else {
      console.log(`[Video API] FAL.ai Sora 2 text-to-video (${duration}s)...`);
      result = (await fal.subscribe("fal-ai/sora-2/text-to-video", {
        input: {
          prompt,
          resolution: "720p",
          aspect_ratio: aspectRatio,
          duration: duration as any,
          delete_video: false,
        },
        logs: true,
      })) as FalVideoResponse;
    }

    return result?.data?.video?.url || result?.video?.url || "";
  } else {
    const duration =
      sceneDuration && sceneDuration <= 4
        ? "4s"
        : sceneDuration && sceneDuration <= 6
          ? "6s"
          : "8s";
    let result: FalVideoResponse;

    if (isHttpUrl) {
      console.log(`[Video API] FAL.ai Veo 3.1 image-to-video (${duration})...`);
      result = (await fal.subscribe("fal-ai/veo3.1/fast/image-to-video", {
        input: {
          prompt,
          image_url: imageUrl,
          aspect_ratio: aspectRatio,
          duration,
          resolution: "720p",
          generate_audio: generateAudio,
        },
        logs: true,
      })) as FalVideoResponse;
    } else {
      console.log(`[Video API] FAL.ai Veo 3.1 text-to-video (${duration})...`);
      result = (await fal.subscribe("fal-ai/veo3.1/fast", {
        input: {
          prompt,
          aspect_ratio: aspectRatio,
          duration,
          resolution: "720p",
          generate_audio: generateAudio,
          auto_fix: true,
        },
        logs: true,
      })) as FalVideoResponse;
    }

    return result?.data?.video?.url || result?.video?.url || "";
  }
}

export default async function handler(req: VercelRequest, res: VercelResponse) {
  // Handle CORS
  if (setupCors(req.method, res)) return;

  if (req.method !== "POST") {
    return res.status(405).json({ error: "Method not allowed" });
  }

  try {
    // Require authentication
    const auth = await requireAuth(req);

    // Apply rate limiting
    const rateLimitKey = createRateLimitKey(auth.userId, auth.orgId);
    const rateLimitOk = await applyRateLimit("video", rateLimitKey, res);
    if (!rateLimitOk) return;

    const {
      prompt,
      aspectRatio,
      model,
      imageUrl,
      sceneDuration,
      generateAudio = true,
    } = req.body as {
      prompt: string;
      aspectRatio: "16:9" | "9:16";
      model: "sora-2" | "veo-3.1";
      imageUrl?: string;
      sceneDuration?: number;
      generateAudio?: boolean;
    };

    if (!prompt || !aspectRatio || !model) {
      return res.status(400).json({
        error: "Missing required fields: prompt, aspectRatio, model",
      });
    }

    console.log(
      `[Video API] Generating video with ${model}, audio: ${generateAudio}`,
    );

    const isHttpUrl = imageUrl && imageUrl.startsWith("http");

    // Calculate expected duration
    const videoDuration =
      model === "sora-2"
        ? 12
        : sceneDuration && sceneDuration <= 4
          ? 4
          : sceneDuration && sceneDuration <= 6
            ? 6
            : 8;

    // Create usage context for tracking
    const usageContext = createUsageContext(
      auth.userId,
      auth.orgId,
      "/api/ai/video",
      "video",
    );

    let usedProvider = "google";
    let modelId = "google-veo-3.0-generate-preview";

    // Track the AI operation
    const blobUrl = await trackAIOperation(
      usageContext,
      "google",
      modelId,
      async () => {
        let videoUrl: string;

        // For Veo 3.1, try Google API first, then fallback to FAL.ai
        if (model === "veo-3.1") {
          try {
            // Try Google Veo API first
            videoUrl = await generateVideoWithGoogleVeo(
              prompt,
              aspectRatio,
              imageUrl,
              sceneDuration,
              generateAudio,
            );
          } catch (googleError: any) {
            // Log the Google API error and fallback to FAL.ai
            console.log(
              `[Video API] Google Veo failed: ${googleError.message}`,
            );
            console.log("[Video API] Falling back to FAL.ai...");
            usedProvider = "fal.ai";
            modelId = isHttpUrl
              ? "fal-ai/veo3.1/fast/image-to-video"
              : "fal-ai/veo3.1/fast";
            videoUrl = await generateVideoWithFal(
              prompt,
              aspectRatio,
              model,
              imageUrl,
              sceneDuration,
              generateAudio,
            );
          }
        } else {
          // For Sora-2 or other models, use FAL.ai directly
          usedProvider = "fal.ai";
          modelId = isHttpUrl
            ? "fal-ai/sora-2/image-to-video"
            : "fal-ai/sora-2/text-to-video";
          videoUrl = await generateVideoWithFal(
            prompt,
            aspectRatio,
            model,
            imageUrl,
            sceneDuration,
            generateAudio,
          );
        }

        if (!videoUrl) {
          throw new Error("Failed to generate video - invalid response");
        }

        console.log(
          `[Video API] Video generated (via ${usedProvider}): ${videoUrl}`,
        );

        // Download video and upload to Vercel Blob for permanent storage
        console.log("[Video API] Uploading to Vercel Blob...");
        const videoResponse = await fetch(videoUrl);
        const videoBlob = await videoResponse.blob();

        const filename = `${model}-video-${Date.now()}.mp4`;
        const blob = await put(filename, videoBlob, {
          access: "public",
          contentType: "video/mp4",
        });

        console.log(`[Video API] Video stored: ${blob.url}`);
        return blob.url;
      },
      (_result, _latencyMs) => ({
        videoDurationSeconds: videoDuration,
        aspectRatio,
        metadata: {
          model,
          provider: usedProvider,
          hasImageInput: !!isHttpUrl,
        },
      }),
    );

    return res.status(200).json({
      success: true,
      url: blobUrl,
      model,
      provider: usedProvider,
    });
  } catch (error: any) {
    console.error("[Video API] Error:", error);

    if (error.name === "AuthenticationError") {
      return res.status(401).json({ error: error.message });
    }

    return res.status(500).json({
      error:
        error instanceof Error ? error.message : "Failed to generate video",
    });
  }
}
